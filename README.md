# simple-VLA
Reproducible and easy-to-use Vision-Language-Action (VLA) baselines.

## TODO

- [ ] **Task & Scene Description**: Design and define tasks using a manipulator in Mujoco. Tasks are yet to be determined, but may include `pick-n-place, push, insert, hang, etc`. Considering both single-arm and bimanipulation scenarios.

- [ ] **Collect Demonstration Pipeline**: A pipeline to collect demonstrations for the defined tasks.

- [ ] **Training**: Implement training procedures for VLA models using the collected demonstrations.

- [ ] **Deploy**: Deploy the trained models for evaluation and real-world testing.
